# 期末报告
## 集成算法

* 集成算法往往是先单独对每个模型进行训练，然后以某种方式结合这些模型的预测结果，最终得到一个总体的更具可靠性的预测结果。目前集成学习算法大多来源于Bagging、Boosting、Stacking三种思想。

#### 自己的话概括
顾名思义，所谓的集成算法其实就是把多个算法的结果汇总起来，从而希望可以得到更好的效果和结果。

#### 概念表达
严格意义上来说，集成学习算法不能算是一种机器学习算法，而像是一种模型优化手段，是一种能在各种机器学习任务上提高准确率的强有力技术。在很多数据挖掘竞赛中，集成学习算法是比赛大杀器，能很好地提升算法的性能。集成学习算法是由多个较弱的模型以一定方法组成集成模型，而这些弱学习器包括SVR、LASSO、KNN等等。Schapire从理论上证明了在知道弱学习器正确率下限的时，可以通过集成算法能将弱学习器提升为强学习器。

#### 定义
集成算法（Emseble Learning）是构建多个学习器，然后通过一定策略结合把它们来完成学习任务的，常常可以获得比单一学习显著优越的学习器。周志华的书上说，“个体学习器的"准确性"和"多样性"本身就存在冲突，一般准确性很高之后，要增加多样性就需牺牲准确性。事实上，如何产生并结合‘好而不同’的个体学习器，恰是集成学习研究的核心”（对准确性和多样性的论述还不是很理解）。

### Bagging算法

#### 自己的话
该算法的基本思路就是训练多个分类器，而各个训练器之间不存在强制的依赖关系，然后再把计算结果求平局值。

#### 概念标准
Bagging

#### 定义
Bagging算法，又称为装袋算法，最初由Leo Breiman于1996年提出，是并行式集成学习的典型代表。Bagging算法主要是从数据层面上设计，使用自助采样法随机有放回地对样本进行采样，构建出样本量相等的相互独立的样本数据集，在同一算法中训练出不同的模型。Bagging算法的集成策略也很简单，对于分类问题，一般通过投票法，以多数模型预测结果为最终结果。

![image](https://img-blog.csdnimg.cn/2021060315284361.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3lvdV9qdXN0X2xvb2s=,size_16,color_FFFFFF,t_70)





















### 参考资料：
————————————————
部分内容为CSDN博主「MonkyK」的原创文章，遵循CC 4.0 BY-SA版权协议，转载请附上原文出处及本声明。
部分内容为CSDN博主「圈外人」的原创文章，遵循CC 4.0 BY-SA版权协议，转载请附上原文出处及本声明。

