# 第十七周

## 词向量
* 「词向量(word vector)」是将词彙转换成包含语意讯息的向量表达的技术。透过类神经网路训练，将词彙从 one-hot encoding 的高维度向量表达，转换成低维度的向量，以利运算的进行。
#### 概念表达
词向量（Word embedding），又叫Word嵌入式自然语言处理（NLP）中的一组语言建模和特征学习技术的统称，其中来自词汇表的单词或短语被映射到实数的向量。 从概念上讲，它涉及从每个单词一维的空间到具有更低维度的连续向量空间的数学嵌入。

生成这种映射的方法包括神经网络，单词共生矩阵的降维，概率模型，可解释的知识库方法，和术语的显式表示 单词出现的背景。
当用作底层输入表示时，单词和短语嵌入已经被证明可以提高NLP任务的性能，例如语法分析和情感分析。

#### 历史
在语言学中，在分布语义学的研究领域中讨论了词嵌入。它旨在基于语言数据的大样本中的分布属性来量化和分类语言项之间的语义相似性。 Firth普及了“一个词以其所保持的特征为特征”的基本观点。
将词语表示为向量的技术起源于20世纪60年代随着用于信息检索的向量空间模型的发展。使用奇异值分解减少维数，然后导致在20世纪80年代后期引入潜在语义分析。2000年Bengio等人。在一系列论文中提供了“神经概率语言模型”，通过“学习单词的分布式表示”来减少语境中单词表示的高维度。 （Bengio等，2003）。单词嵌入有两种不同的风格，一种是将单词表示为共同出现的单词的向量，另一种是将单词表示为单词出现的语言上下文的向量;研究了这些不同的风格（Lavelli等，2004）。Roweis和Saul在“科学”杂志上发表了如何使用“局部线性嵌入”（LLE）来发现高维数据结构的表示。该区域在2010年后逐渐发展并真正起飞，部分原因是此后在向量质量和模型训练速度方面取得了重要进展。

![image](https://user-images.githubusercontent.com/62127656/122322900-cd196f80-cf58-11eb-81fe-e68f1317bc7f.png)
![image](https://user-images.githubusercontent.com/62127656/122333465-cc89d480-cf6a-11eb-972f-52ea0376eb85.png)

#### 限制
单词嵌入（一般的单词向量空间模型）的主要限制之一是单词的可能含义被混合成单个表示（语义空间中的单个向量）。 Sense embeddings 是这个问题的解决方案：单词的个体含义在空间中表示为不同的向量。

#### 对于生物序列：BioVectors
Asgari和Mofrad已经提出了用于生物信息学应用的生物序列（例如DNA，RNA和蛋白质）中n-gram的词嵌入。命名生物载体（BioVec）通常指蛋白质载体（ProtVec）用于蛋白质（氨基酸序列）和基因载体（GeneVec）用于基因序列的生物序列，这种表示可广泛用于深层应用学习蛋白质组学和基因组学。 Asgari和Mofrad 提出的结果表明，BioVectors可以根据对潜在模式的生物化学和生物物理学解释来描述生物序列。

> 参考资料：百度百科
