# 第十六周

## 机器学习
* 机器学习理论主要是设计和分析一些让电脑可以自动「学习」的演算法。
#### 概念表达
机器学习是一门多领域交叉学科，涉及概率论、统计学、逼近论、凸分析、算法复杂度理论等多门学科。专门研究计算机怎样模拟或实现人类的学习行为，以获取新的知识或技能，重新组织已有的知识结构使之不断改善自身的性能。

它是人工智能核心，是使计算机具有智能的根本途径。

#### 定义
机器学习是一门多学科交叉专业，涵盖概率论知识，统计学知识，近似理论知识和复杂算法知识，使用计算机作为工具并致力于真实实时的模拟人类学习方式，并将现有内容进行知识结构划分来有效提高学习效率。 [1] 
机器学习有下面几种定义：
* 机器学习是一门人工智能的科学，该领域的主要研究对象是人工智能，特别是如何在经验学习中改善具体算法的性能。
* 机器学习是对能通过经验自动改进的计算机算法的研究。
* 机器学习是用数据或以往的经验，以此优化计算机程序的性能标准。

#### 历史
机器学习实际上已经存在了几十年或者也可以认为存在了几个世纪。追溯到17世纪，贝叶斯、拉普拉斯关于最小二乘法的推导和马尔可夫链，这些构成了机器学习广泛使用的工具和基础。1950年（艾伦.图灵提议建立一个学习机器）到2000年初（有深度学习的实际应用以及最近的进展，比如2012年的AlexNet），机器学习有了很大的进展。

## 蒙地卡罗方法
* 擁有一個四分之一圓(以內為紅色以外為藍色)
* 蒙地卡羅方法（英語：Monte Carlo method），也稱統計類比方法，是1940年代中期由於科學技術的發展和電腦的發明，而提出的一種以機率統計理論為指導的數值計算方法。是指使用亂數（或更常見的偽亂數）來解決很多計算問題的方法。
![image](https://user-images.githubusercontent.com/47874872/123469862-31f25b00-d626-11eb-95ad-38cdc480cd44.png)
#### 概念表达
蒙特卡罗方法（英语：Monte Carlo method），也称统计模拟方法，是1940年代中期由于科学技术的发展和电子计算机的发明，而提出的一种以概率统计理论为指导的数值计算方法。是指使用随机数（或更常见的伪随机数）来解决很多计算问题的方法。
#### 定义
通常蒙特卡罗方法可以粗略地分成两类：一类是所求解的问题本身具有内在的随机性，借助计算机的运算能力可以直接模拟这种随机的过程。例如在核物理研究中，分析中子在反应堆中的传输过程。中子与原子核作用受到量子力学规律的制约，人们只能知道它们相互作用发生的概率，却无法准确获得中子与原子核作用时的位置以及裂变产生的新中子的行进速率和方向。科学家依据其概率进行随机抽样得到裂变位置、速度和方向，这样模拟大量中子的行为后，经过统计就能获得中子传输的范围，作为反应堆设计的依据。

另一种类型是所求解问题可以转化为某种随机分布的特征数，比如随机事件出现的概率，或者随机变量的期望值。通过随机抽样的方法，以随机事件出现的频率估计其概率，或者以抽样的数字特征估算随机变量的数字特征，并将其作为问题的解。这种方法多用于求解复杂的多维积分问题。
#### 历史
蒙特卡罗方法（英语：Monte Carlo method），也称统计模拟方法，是1940年代中期由于科学技术的发展和电子计算机的发明，而提出的一种以概率统计理论为指导的数值计算方法。是指使用随机数（或更常见的伪随机数）来解决很多计算问题的方法。

20世纪40年代，在冯·诺伊曼，斯塔尼斯拉夫·乌拉姆和尼古拉斯·梅特罗波利斯在洛斯阿拉莫斯国家实验室为核武器计划工作时，发明了蒙特卡罗方法。因为乌拉姆的叔叔经常在摩纳哥的蒙特卡洛赌场输钱得名，而蒙特卡罗方法正是以概率为基础的方法。

## 马可夫键
#### 概念表达
马尔可夫模型（Markov Model）是一种统计模型，广泛应用在语音识别，词性自动标注，音字转换，概率文法等各个自然语言处理等应用领域。经过长期发展，尤其是在语音识别中的成功应用，使它成为一种通用的统计工具。

为状态空间中经过从一个状态到另一个状态的转换的随机过程。该过程要求具备「无记忆」的性质：下一状态的机率分布只能由当前状态决定，在时间序列中它前面的事件均与之无关。这种特定类型的「无记忆性」称作马可夫性质。马尔科夫链作为实际过程的统计模型具有许多应用。

在马可夫链的每一步，系统根据机率分布，可以从一个状态变到另一个状态，也可以保持当前状态。状态的改变叫做转移，与不同的状态改变相关的机率叫做转移机率。随机漫步就是马可夫链的例子。随机漫步中每一步的状态是在图形中的点，每一步可以移动到任何一个相邻的点，在这裡移动到每一个点的机率都是相同的（无论之前漫步路径是如何的）。
* 讨论不是互相独立的一些事件。
* 下一状态的机率分布只能由当前状态决定，在时间序列中它前面的事件均与之无关。
* 种具有状态的随机过程
* ex: 转移矩阵的应用问题

![image](https://user-images.githubusercontent.com/47874872/123469942-4afb0c00-d626-11eb-9c9e-e66e4dd9d0a5.png)

## 隐藏马可夫模型
* 隐藏式马可夫模型（Hidden Markov Model；缩写：HMM）或称作隐性马可夫模型，是统计模型，它用来描述一个含有隐含未知参数的马可夫过程。其难点是从可观察的参数中确定该过程的隐含参数。然后利用这些参数来作进一步的分析，例如图型识别。
#### 概念表达
隐藏马可夫模型(Hidden Markov Model, HMM)是一连串事件接续发生的机率，用以探索看不到的世界/现象/事实的数学工具，是机器学习（Machine Learning）领域中常常用到的理论模型，从语音识别（Speech Recognition）、手势辨识（gesture recognition），到生物信息学（Bioinformatics），都可以见到其身影。
#### 定义
我们通常都习惯寻找一个事物在一段时间里的变化模式（规律）。
马可夫在1906年首先做出了这类过程。而将此一般化到可数无限状态空间是由柯尔莫果洛夫在1936年给出的。马可夫链与布朗运动以及遍历假说这两个二十世纪初期物理学重要课题是相联系的。

## 吉布斯採样
是统计学中用于马尔科夫蒙特卡洛（MCMC）的一种算法，用于在难以直接採样时从某一多变量概率分布中近似抽取样本序列。该序列可用于近似联合分布、部分变量的边缘分布或计算积分（如某一变量的期望值）。某些变量可能为已知变量，故对这些变量并不需要採样。

## 维特比算法
#### 概念表达
维特比算法是一种动态规划算法用于寻找最有可能产生观测事件序列的-维特比路径-隐含状态序列，特别是在马尔可夫信息源上下文和隐马尔可夫模型中。术语“维特比路径”和“维特比算法”也被用于寻找观察结果最有可能解释相关的动态规划算法。例如在统计句法分析中动态规划算法可以被用于发现最可能的上下文无关的派生(解析)的字符串，有时被称为“维特比分析”。
#### 历史
维特比算法由安德鲁·维特比(Andrew Viterbi)于1967年提出，用于在数字通信链路中解卷积以消除噪音。 此算法被广泛应用于CDMA和GSM数字蜂窝网络、拨号调制解调器、卫星、深空通信和802.11无线网络中解卷积码。现今也被常常用于语音识别、关键字识别、计算语言学和生物信息学中。例如在语音(语音识别)中，声音信号作为观察到的事件序列，而文本字符串，被看作是隐含的产生声音信号的原因，因此可对声音信号应用维特比算法寻找最有可能的文本字符串。

## 最大期望演算法
#### 概念表达
最大期望算法（Expectation-Maximization algorithm, EM），或Dempster-Laird-Rubin算法，是一类通过迭代进行极大似然估计（Maximum Likelihood Estimation, MLE）的优化算法，通常作为牛顿迭代法（Newton-Raphson method）的替代用于对包含隐变量（latent variable）或缺失数据（incomplete-data）的概率模型进行参数估计
#### 定义
EM算法的标准计算框架由E步（Expectation-step）和M步（Maximization step）交替组成，算法的收敛性可以确保迭代至少逼近局部极大值。EM算法是MM算法（Minorize-Maximization algorithm）的特例之一，有多个改进版本，包括使用了贝叶斯推断的EM算法、EM梯度算法、广义EM算法等。
由于迭代规则容易实现并可以灵活考虑隐变量，EM算法被广泛应用于处理数据的缺测值，以及很多机器学习（machine learning）算法，包括高斯混合模型（Gaussian Mixture Model, GMM）和隐马尔可夫模型（Hidden Markov Model, HMM）的参数估计。
#### 历史
EM算法的正式提出来自美国数学家Arthur Dempster、Nan Laird和Donald Rubin，其在1977年发表的研究对先前出现的作为特例的EM算法进行了总结并给出了标准算法的计算步骤，EM算法也由此被称为Dempster-Laird-Rubin算法。1983年，美国数学家吴建福（C.F. Jeff Wu）给出了EM算法在指数族分布以外的收敛性证明。


## K-近邻演算法
* 透过找出附近邻居的分类定义来自己的类别。

![image](https://user-images.githubusercontent.com/62127656/121561595-3bd36600-ca4b-11eb-9c0c-c4a4e054d1b2.png)
## 决策树(Decision Tree)
* 决策树建立并用来辅助决策，是一种特殊的树结构。
* 它是一个算法显示的方法。决策树经常在运筹学中使用，特别是在决策分析中，它帮助确定一个能最可能达到目标的策略。 

![image](https://user-images.githubusercontent.com/62127656/121563319-e1d3a000-ca4c-11eb-9964-93369680a93f.png)

## 随机森林(Random Forest)
* 近几年随机森林非常受到青睐，被运用在大量的机器学习应用中
* 随机森林是一个包含多个决策树的分类器，并且其输出的类别是由个别树输出的类别的众数而定。
* 随机森林是由很多决策树构成的，不同决策树之间没有关联。

![image](https://user-images.githubusercontent.com/62127656/121564216-cc12aa80-ca4d-11eb-8bf4-60de02c5445d.png)

## 支援向量机 Support Vector Machine (SVM)
* 是一种二分类模型
* 在分类与迴归分析中分析资料的监督式学习模型与相关的学习演算法。

> 参考资料：百度百科、知乎
